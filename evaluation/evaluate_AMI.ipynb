{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:14.788704Z",
     "start_time": "2025-04-10T08:56:14.764502Z"
    }
   },
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from embeddings.embedding_utils import get_queries, get_query_key\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:14.853495Z",
     "start_time": "2025-04-10T08:56:14.822144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_clustering(query_key, embedding_algo, clustering_algo):\n",
    "    embedding_algo_name=embedding_algo.__module__.split(\".\")[-1]+\"__\"+embedding_algo.__name__\n",
    "    clustering_algo_name=clustering_algo.__name__\n",
    "    filename = f\"../cluster_results/{embedding_algo_name}/{clustering_algo_name}/{query_key}.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return np.array(data_dict[\"embeddings\"]),np.array(data_dict[\"clusters\"]), pd.Series(data_dict[\"numerical_labels_true\"]), data_dict[\"categorizer\"]\n",
    "\n",
    "def load_original_document(query_key):\n",
    "    filename = f\"../query_results/{query_key}.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict[\"data\"]"
   ],
   "id": "ca2dcd3a4229c842",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:14.929175Z",
     "start_time": "2025-04-10T08:56:14.913781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_noise_entries(numerical_label_lists, assigned_labels):\n",
    "    no_noise_indices= np.array(assigned_labels) != -1\n",
    "    return numerical_label_lists[no_noise_indices], np.array(assigned_labels)[no_noise_indices]\n",
    "\n",
    "def make_noise_cluster(assigned_labels):\n",
    "    noise_indices= np.array(assigned_labels) == -1\n",
    "    free_cluster_label = len(set(assigned_labels))\n",
    "    new_labels = np.array(assigned_labels)\n",
    "    new_labels[noise_indices] = free_cluster_label\n",
    "    return new_labels"
   ],
   "id": "5fd3b93e1e46e954",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:14.989387Z",
     "start_time": "2025-04-10T08:56:14.966588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_singe_label_gts(numerical_label_lists):\n",
    "    flatlist = [item for sublist in numerical_label_lists for item in sublist]\n",
    "    gts = []\n",
    "    for label in set(flatlist):\n",
    "        single_labels = []\n",
    "        for sublist in numerical_label_lists:\n",
    "            if label in sublist:\n",
    "                single_labels.append(1)\n",
    "            else:\n",
    "                single_labels.append(0)\n",
    "        gts.append(single_labels)\n",
    "    return gts"
   ],
   "id": "b163cef34e28ffe5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:15.036880Z",
     "start_time": "2025-04-10T08:56:15.024306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "\n",
    "def get_combined_AMI(clustering_labels, singe_label_gts):\n",
    "    sizes = [sum(sigle_label_gt) for sigle_label_gt in singe_label_gts]\n",
    "    ami_s = []\n",
    "    for i in range(len(singe_label_gts)):\n",
    "        ami_s.append(adjusted_mutual_info_score(clustering_labels, singe_label_gts[i]))\n",
    "    return np.average(ami_s, weights=sizes)"
   ],
   "id": "ef18e6ccb2728ce3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:56:15.084530Z",
     "start_time": "2025-04-10T08:56:15.068948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from embeddings.tf_idf import get_embedding_pca as tf_idf_pca\n",
    "from embeddings.fasttext import get_embedding_combined_polling_pca\n",
    "from embeddings.openai_api import get_embedding as embedding_openai\n",
    "\n",
    "from clustering.clusterings import kmeans_with_estimated_k,xmeans_clustering, hdbscan_clustering, agglomerative_clustering_with_estimated_k\n",
    "\n",
    "data_queries = get_queries()\n",
    "embedding_algos = [tf_idf_pca,get_embedding_combined_polling_pca, embedding_openai]\n",
    "clustering_algos = [kmeans_with_estimated_k,xmeans_clustering, agglomerative_clustering_with_estimated_k]\n",
    "clustering_algos_noise = [hdbscan_clustering]"
   ],
   "id": "217296d4bafe3deb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:57:06.481223Z",
     "start_time": "2025-04-10T08:56:15.152463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AMI_matrix = np.zeros((4,5,len(embedding_algos),len(clustering_algos)+2*len(clustering_algos_noise)))\n",
    "\n",
    "\n",
    "string_to_num_translator = {}\n",
    "num_to_string_translator = {}\n",
    "for i_0, category in tqdm(enumerate(data_queries.keys()),desc=\"Categories\"):\n",
    "    string_to_num_translator[\"0:\"+category] = i_0\n",
    "    num_to_string_translator[\"0:\" + str(i_0)] = category\n",
    "    for i_1, query in enumerate(data_queries[category]):\n",
    "        string_to_num_translator[\"1:\"+query] = i_1\n",
    "        num_to_string_translator[\"1:\" + str(i_1)] = query\n",
    "        query_key = get_query_key(category, query)\n",
    "\n",
    "        doc_set_label_idf = None\n",
    "\n",
    "        for i_2, embedding_algo in enumerate(embedding_algos):\n",
    "            embedding_algo_name = embedding_algo.__module__.split(\".\")[-1] + \"__\" + embedding_algo.__name__\n",
    "            string_to_num_translator[\"2:\"+embedding_algo_name] = i_2\n",
    "            num_to_string_translator[\"2:\"+str(i_2)] = embedding_algo_name\n",
    "\n",
    "            for i_3, cluster_algo in enumerate(clustering_algos):\n",
    "                cluster_algo_name = cluster_algo.__name__\n",
    "                string_to_num_translator[\"3:\"+cluster_algo_name] = i_3\n",
    "                num_to_string_translator[\"3:\"+str(i_3)] = cluster_algo_name\n",
    "                embedding, cluster_labels, numerical_labels_true, _ = load_clustering(query_key, embedding_algo, cluster_algo)\n",
    "\n",
    "                #fresh ground truth\n",
    "                singe_label_gts = get_singe_label_gts(numerical_labels_true)\n",
    "\n",
    "                combined_AMI= get_combined_AMI(cluster_labels, singe_label_gts)\n",
    "                AMI_matrix[i_0,i_1,i_2,i_3] = combined_AMI\n",
    "\n",
    "            for i_3, cluster_algo in enumerate(clustering_algos_noise):\n",
    "                i_3 = 2 * i_3 + len(clustering_algos)\n",
    "                cluster_algo_name = cluster_algo.__name__+\" no noise\"\n",
    "                string_to_num_translator[\"3:\"+cluster_algo_name] = i_3\n",
    "                num_to_string_translator[\"3:\"+str(i_3)] = cluster_algo_name\n",
    "\n",
    "                embedding, cluster_labels, numerical_labels_true, _ = load_clustering(query_key, embedding_algo, cluster_algo)\n",
    "                numerical_labels_true_no_noise, labels_no_noise= remove_noise_entries(numerical_labels_true, cluster_labels)\n",
    "\n",
    "                singe_label_gts_no_noise = get_singe_label_gts(numerical_labels_true_no_noise)\n",
    "\n",
    "\n",
    "                combined_AMI= get_combined_AMI(labels_no_noise, singe_label_gts_no_noise)\n",
    "                AMI_matrix[i_0,i_1,i_2,i_3] = combined_AMI\n",
    "\n",
    "                i_3+=1\n",
    "                cluster_algo_name = cluster_algo.__name__+\" noise cluster\"\n",
    "                num_to_string_translator[\"3:\"+str(i_3)] = cluster_algo_name\n",
    "                string_to_num_translator[\"3:\"+cluster_algo_name] = i_3\n",
    "\n",
    "                labels_noise_cluster= make_noise_cluster(cluster_labels)\n",
    "\n",
    "                #fresh ground truth\n",
    "                singe_label_gts = get_singe_label_gts(numerical_labels_true)\n",
    "\n",
    "                combined_AMI= get_combined_AMI(labels_noise_cluster, singe_label_gts)\n",
    "                AMI_matrix[i_0,i_1,i_2,i_3] = combined_AMI"
   ],
   "id": "25532b33ecc3d5ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categories: 4it [00:51, 12.82s/it]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:57:06.530377Z",
     "start_time": "2025-04-10T08:57:06.508007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_function(category, query, embedding_algo_name, cluster_algo_name):\n",
    "    i_0=string_to_num_translator[\"0:\"+category]\n",
    "    i_1=string_to_num_translator[\"1:\"+query]\n",
    "    i_2=string_to_num_translator[\"2:\"+embedding_algo_name]\n",
    "    i_3=string_to_num_translator[\"3:\"+cluster_algo_name]\n",
    "    value = AMI_matrix[i_0,i_1,i_2,i_3]\n",
    "    return f\"{value:.3f}\"\n"
   ],
   "id": "5a5be7519497f66a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:57:06.678673Z",
     "start_time": "2025-04-10T08:57:06.661014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make the header of the table\n",
    "column_main_labels = [embedding_algo.__module__.split(\".\")[-1] + \"__\" + embedding_algo.__name__ for embedding_algo in\n",
    "                      embedding_algos]\n",
    "column_sub_labels = [cluster_algo.__name__ for cluster_algo in clustering_algos]\n",
    "column_sub_labels.extend([cluster_algo.__name__ + \" no noise\" for cluster_algo in clustering_algos_noise])\n",
    "column_sub_labels.extend([cluster_algo.__name__ + \" noise cluster\" for cluster_algo in clustering_algos_noise])\n",
    "row_main_labels = [category for category in data_queries.keys()]\n",
    "row_sub_labels = [data_queries[category] for category in data_queries.keys()]"
   ],
   "id": "8e78bc8ed9fe71aa",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:57:53.322610Z",
     "start_time": "2025-04-10T08:57:53.299363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_col_main = len(column_main_labels)\n",
    "num_col_sub = len(column_sub_labels)\n",
    "num_row_main = len(row_main_labels)\n",
    "bkslsh=\"\\\\\"\n",
    "escaped_ = r\"\\_\"\n",
    "latex_code = r\"  \\begin{tabular}{|l|c|*{\" + str(num_col_main * num_col_sub) + r\"}{c|}}\" + \"\\n\"\n",
    "latex_code += r\"    \\hline\" + \"\\n\"\n",
    "latex_code += r\"    \\multicolumn{2}{|c|}{\\multirow{2}{*}{}} &\"\n",
    "for i, main_label in enumerate(column_main_labels):\n",
    "    latex_code += rf\" \\multicolumn{{{num_col_sub}}}{{c|}}{{{main_label}}}\"\n",
    "    if i < num_col_main - 1:\n",
    "        latex_code += \" &\"\n",
    "latex_code += r\" \\\\\" + \"\\n\"\n",
    "latex_code += r\"    \\cline{3-\" + str(2 + num_col_main * num_col_sub) + \"}\" + \"\\n\"\n",
    "latex_code += r\"    \\multicolumn{2}{|c|}{} &\"\n",
    "for j in range(len(column_main_labels)):\n",
    "    for i, sub_label in enumerate(column_sub_labels):\n",
    "        latex_code += rf\" \\multicolumn{{1}}{{c|}}{{\\rotatebox{{90}}{{{sub_label.replace('_', escaped_)}~}}}}\"\n",
    "        if i < len(column_sub_labels) - 1 or j < len(column_main_labels) - 1:\n",
    "            latex_code += \" &\"\n",
    "latex_code += r\" \\\\\" + \"\\n\"\n",
    "latex_code += r\"    \\hline\" + \"\\n\"\n",
    "\n",
    "avges = np.zeros((len(column_main_labels)*len(column_sub_labels)))\n",
    "scores = np.zeros((len(row_main_labels)*len(row_sub_labels[0]),len(column_main_labels)*len(column_sub_labels)))\n",
    "\n",
    "for i, main_label in enumerate(row_main_labels):\n",
    "    num_sub_rows = len(row_sub_labels[i])\n",
    "    latex_code += rf\"    \\multirow{{{num_sub_rows}}}{{*}}{{\\rotatebox{{90}}{{\\makecell{{{main_label}}}}}}}\"\n",
    "    for j, sub_label in enumerate(row_sub_labels[i]):\n",
    "        latex_code += f\" & {sub_label} &\"\n",
    "        for col_main_idx, col_main in enumerate(column_main_labels):\n",
    "            for col_sub_idx, col_sub in enumerate(column_sub_labels):\n",
    "                data = data_function(main_label, sub_label, col_main, col_sub)\n",
    "                latex_code += f\" {data.replace('0.','.')}\"\n",
    "                if col_main_idx < num_col_main - 1 or col_sub_idx < len(column_sub_labels) - 1:\n",
    "                    latex_code += \" &\"\n",
    "                avges[col_main_idx * len(column_sub_labels) + col_sub_idx] += float(data)\n",
    "                scores[i*num_sub_rows+j][col_main_idx * len(column_sub_labels) + col_sub_idx] = float(data)\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "    latex_code += r\"    \\hline\" + \"\\n\"\n",
    "\n",
    "avges/=len(row_main_labels)*5\n",
    "latex_code += rf\"\"\"    \\hline\n",
    "    & Average & {' & '.join([bkslsh+f'textbf{{{avg_val:.3f}}}'.replace('0.','.') for avg_val in avges])}\\\\\n",
    "    \\hline\"\"\"+\"\\n\"\n",
    "latex_code += r\"  \\end{tabular}\" + \"\\n\"\n",
    "print(latex_code)"
   ],
   "id": "68ae74eedcbbdd37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \\begin{tabular}{|l|c|*{15}{c|}}\n",
      "    \\hline\n",
      "    \\multicolumn{2}{|c|}{\\multirow{2}{*}{}} & \\multicolumn{5}{c|}{tf_idf__get_embedding_pca} & \\multicolumn{5}{c|}{fasttext__get_embedding_combined_polling_pca} & \\multicolumn{5}{c|}{openai_api__get_embedding} \\\\\n",
      "    \\cline{3-17}\n",
      "    \\multicolumn{2}{|c|}{} & \\multicolumn{1}{c|}{\\rotatebox{90}{kmeans\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{xmeans\\_clustering~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{agglomerative\\_clustering\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering no noise~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering noise cluster~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{kmeans\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{xmeans\\_clustering~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{agglomerative\\_clustering\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering no noise~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering noise cluster~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{kmeans\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{xmeans\\_clustering~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{agglomerative\\_clustering\\_with\\_estimated\\_k~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering no noise~}} & \\multicolumn{1}{c|}{\\rotatebox{90}{hdbscan\\_clustering noise cluster~}} \\\\\n",
      "    \\hline\n",
      "    \\multirow{5}{*}{\\rotatebox{90}{\\makecell{Computer Science and AI}}} & Transformer models & .030 & .004 & .055 & .069 & .034 & .004 & .006 & .026 & .019 & .006 & .080 & .054 & .070 & .093 & .044 \\\\\n",
      " & Federated learning & .025 & .024 & .027 & .032 & .015 & .006 & .003 & .007 & .003 & .003 & .036 & .041 & .033 & .034 & .021 \\\\\n",
      " & Quantum computing & .045 & .069 & .045 & .063 & .025 & .033 & .031 & .027 & .034 & .019 & .057 & .057 & .047 & .047 & .031 \\\\\n",
      " & Explainable AI & .016 & .023 & .027 & .028 & .013 & .005 & .010 & .003 & .012 & .005 & .045 & .056 & .053 & .077 & .036 \\\\\n",
      " & Graph neural networks & .031 & .032 & .038 & .038 & .019 & .004 & .002 & .002 & .009 & .004 & .025 & .028 & .030 & .038 & .024 \\\\\n",
      "    \\hline\n",
      "    \\multirow{5}{*}{\\rotatebox{90}{\\makecell{Physics and Engineering}}} & Topological insulators & .038 & .026 & .032 & .055 & .026 & .015 & .012 & .013 & .014 & .008 & .049 & .043 & .040 & .047 & .030 \\\\\n",
      " & Optical metamaterials & -.014 & -.010 & -.008 & -.028 & -.019 & .004 & .003 & -.008 & -.020 & -.017 & -.008 & -.016 & -.011 & -.012 & -.014 \\\\\n",
      " & Fission & .092 & .034 & .088 & .086 & .055 & .051 & .008 & .041 & .064 & .041 & .096 & .104 & .098 & .082 & .064 \\\\\n",
      " & Soft robotics & -.001 & .041 & .229 & .192 & .089 & -.003 & .034 & .045 & .044 & .045 & .197 & .293 & .196 & .223 & .160 \\\\\n",
      " & Health monitoring & .022 & .019 & .026 & .026 & .013 & .004 & .002 & .008 & .007 & .006 & .041 & .024 & .038 & .049 & .032 \\\\\n",
      "    \\hline\n",
      "    \\multirow{5}{*}{\\rotatebox{90}{\\makecell{Biology and Medicine}}} & CRISPR & .032 & .045 & .183 & .114 & .098 & .079 & .097 & .105 & .182 & .094 & .126 & .130 & .132 & .172 & .108 \\\\\n",
      " & Microbiome & .079 & .070 & .068 & .030 & .018 & .041 & .004 & .046 & .051 & .024 & .119 & .127 & .125 & .089 & .037 \\\\\n",
      " & DNA sequencing & .096 & .106 & .096 & .061 & .039 & .016 & .026 & .025 & .058 & .026 & .103 & .099 & .099 & .087 & .062 \\\\\n",
      " & Synthetic biology & .013 & .016 & .008 & .047 & .016 & .002 & .007 & .009 & .019 & .009 & .029 & .039 & .034 & .048 & .037 \\\\\n",
      " & Drug delivery & .015 & .002 & .034 & .044 & .024 & .001 & .004 & .005 & .001 & .000 & .057 & .054 & .047 & .056 & .036 \\\\\n",
      "    \\hline\n",
      "    \\multirow{5}{*}{\\rotatebox{90}{\\makecell{Earth and Environmental Science}}} & Climate model & .069 & .105 & .082 & .088 & .046 & .045 & .039 & .047 & .066 & .035 & .086 & .115 & .087 & .094 & .059 \\\\\n",
      " & Remote sensing & .090 & .128 & .080 & .074 & .038 & .051 & .061 & .051 & .042 & .024 & .100 & .143 & .094 & .077 & .054 \\\\\n",
      " & Greenhouse gas & .038 & .045 & .061 & .075 & .034 & .022 & .014 & .024 & .037 & .018 & .064 & .066 & .080 & .072 & .052 \\\\\n",
      " & Biodiversity & .063 & .088 & .070 & .096 & .046 & .028 & .014 & .009 & .031 & .014 & .088 & .105 & .089 & .089 & .063 \\\\\n",
      " & Light pollution & .007 & -.003 & .001 & .005 & -.001 & .005 & .000 & .059 & .050 & .021 & -.004 & .054 & .014 & -.003 & .001 \\\\\n",
      "    \\hline\n",
      "    \\hline\n",
      "    & Average & \\textbf{.039} & \\textbf{.043} & \\textbf{.062} & \\textbf{.060} & \\textbf{.031} & \\textbf{.021} & \\textbf{.019} & \\textbf{.027} & \\textbf{.036} & \\textbf{.019} & \\textbf{.069} & \\textbf{.081} & \\textbf{.070} & \\textbf{.073} & \\textbf{.047}\\\\\n",
      "    \\hline\n",
      "  \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T09:00:44.660756Z",
     "start_time": "2025-04-10T09:00:44.644726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "variances = np.std(scores,axis=0)\n",
    "print(f\"\"\"& St.deviation & {' & '.join([bkslsh+f'textbf{{{avg_val:.3f}}}'.replace('0.','.') for avg_val in variances])}\\\\\\\\\n",
    "    \\hline\"\"\")"
   ],
   "id": "eb9781fd64689902",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& St.deviation & \\textbf{.031} & \\textbf{.038} & \\textbf{.056} & \\textbf{.044} & \\textbf{.027} & \\textbf{.022} & \\textbf{.024} & \\textbf{.026} & \\textbf{.040} & \\textbf{.022} & \\textbf{.047} & \\textbf{.063} & \\textbf{.046} & \\textbf{.051} & \\textbf{.036}\\\n",
      "    \\hline\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
